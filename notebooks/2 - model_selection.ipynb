{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "X_test = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_train = np.array(pd.read_csv(\"../data/processed/y_train.csv\")).reshape(-1)\n",
    "y_test = np.array(pd.read_csv(\"../data/processed/y_test.csv\")).reshape(-1)\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "supp_vec = SVR().fit(X_train, y_train)\n",
    "rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "grad = XGBRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-exponentiate the target so we're in actual units of dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred = np.exp(ridge.predict(X_test))\n",
    "supp_vec_pred = np.exp(supp_vec.predict(X_test))\n",
    "rf_pred = np.exp(rf.predict(X_test))\n",
    "grad_pred = np.exp(grad.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "predictions = {'Ridge Regression': ridge_pred,\n",
    "               'SVR': supp_vec_pred,\n",
    "               'Random Forest': rf_pred,\n",
    "               'Gradient Boosting': grad_pred}\n",
    "\n",
    "n = len(y_test)\n",
    "\n",
    "# Compute metrics\n",
    "for model_name, y_pred in predictions.items():\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    p = X_test.shape[1]\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    \n",
    "    metrics[model_name] = {'MSE': mse,\n",
    "                           'RMSE': rmse,\n",
    "                           'MAE': mae,\n",
    "                           'R-squared': r2,\n",
    "                           'Adjusted R-squared': adj_r2}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge Regression</th>\n",
       "      <th>SVR</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.16e+11</td>\n",
       "      <td>7.09e+09</td>\n",
       "      <td>1.11e+10</td>\n",
       "      <td>8.60e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.65e+05</td>\n",
       "      <td>8.42e+04</td>\n",
       "      <td>1.05e+05</td>\n",
       "      <td>2.93e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.25e+05</td>\n",
       "      <td>4.34e+04</td>\n",
       "      <td>1.35e+04</td>\n",
       "      <td>8.71e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>4.76e-01</td>\n",
       "      <td>9.83e-01</td>\n",
       "      <td>9.73e-01</td>\n",
       "      <td>9.98e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <td>4.42e-01</td>\n",
       "      <td>9.82e-01</td>\n",
       "      <td>9.71e-01</td>\n",
       "      <td>9.98e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Ridge Regression       SVR Random Forest Gradient Boosting\n",
       "MSE                        2.16e+11  7.09e+09      1.11e+10          8.60e+08\n",
       "RMSE                       4.65e+05  8.42e+04      1.05e+05          2.93e+04\n",
       "MAE                        1.25e+05  4.34e+04      1.35e+04          8.71e+03\n",
       "R-squared                  4.76e-01  9.83e-01      9.73e-01          9.98e-01\n",
       "Adjusted R-squared         4.42e-01  9.82e-01      9.71e-01          9.98e-01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics).map(lambda x: \"{:.2e}\".format(x))\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost wins on every metric and it isn't close\n",
    "\n",
    "In terms of evaluating criteria:\n",
    "\n",
    "RMSE, MSE, $R^2$ and Adj $R^2$ are all linked to the squared error. RMSE has the benefit of being interpretable in terms of actual units, and $R^2$ gives a good relative measure of success.\n",
    "\n",
    "MAE is linked to the observed error, not the model's loss function (squared error).\n",
    "\n",
    "Overall, the strongest selectors for model fit are RMSE, MSE, $R^2$ and Adj $R^2$ - these are all linked to the actual squared error and therefore give the best indication of model fit.\n",
    "\n",
    "MAE is suitable as a reporting metric to stakeholders, but isn't suitable for model selection because it is only indirectly linked to goodness of fit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future goal to explore methods such as RFECV or Forward/Backward selection to reduce the model's dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
